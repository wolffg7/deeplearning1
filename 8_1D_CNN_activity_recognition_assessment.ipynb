{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wolffg7/deeplearning1/blob/main/8_1D_CNN_activity_recognition_assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bkHwspbXK2s"
      },
      "source": [
        "# Copyright\n",
        "<pre>\n",
        "You may use and modify this code for research and development purpuses.\n",
        "Using this code for educational purposes (self-paced or instructor led) without the permission of the author is prohibited.\n",
        "Copyright (c) 2023 Bálint Gyires-Tóth - All Rights Reserved\n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0kz73yNXK2t"
      },
      "source": [
        "In this notebook, we will classify human activities based on smartphone accelerometer and gyroscope data. The corresponding Human Activity Recognition Using Smartphones Data Set is delivered by UCI Machine Learning Repository, for more information [please visit the site](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data acquisition\n",
        "Lets download and unpack the data."
      ],
      "metadata": {
        "id": "zy5lL5OEKvZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv5CJEQfKvFT",
        "outputId": "9ede9cad-015a-450c-8190-94bcbcbe697a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-12 16:34:30--  https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60999314 (58M) [application/x-httpd-php]\n",
            "Saving to: ‘UCI HAR Dataset.zip.1’\n",
            "\n",
            "UCI HAR Dataset.zip 100%[===================>]  58.17M  16.7MB/s    in 4.4s    \n",
            "\n",
            "2023-04-12 16:34:35 (13.1 MB/s) - ‘UCI HAR Dataset.zip.1’ saved [60999314/60999314]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"UCI HAR Dataset.zip\" > null"
      ],
      "metadata": {
        "id": "9_bgc7Y2GTpy",
        "outputId": "b3fadf09-ef4c-4248-ca15-476fce1d6142",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace UCI HAR Dataset/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Imports\n",
        "In this notebook we will need the following packages."
      ],
      "metadata": {
        "id": "A8IHEttFHzUv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWBNCVa0bf65"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, Conv1D, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Loading the data\n",
        "The following functions will load the training and test data from the unpacked dataset."
      ],
      "metadata": {
        "id": "uzBI0j52H_sL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this function loads a single file (input or output)\n",
        "def load_file(filepath):\n",
        "  df = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
        "  return df.values\n",
        "\n",
        "# this function loads a set of files into a Numpy array with a shape of [samples, timesteps, features]\n",
        "def load_group(filenames, prefix=''):\n",
        "  loaded = list()\n",
        "  for name in filenames:\n",
        "    data = load_file(prefix + name)\n",
        "    loaded.append(data)\n",
        "    # stack group so that features are the 3rd dimension\n",
        "  loaded = np.dstack(loaded)\n",
        "  return loaded\n",
        "\n",
        " # load inputs and outputs from a directory\n",
        "def load_XY(group, path):\n",
        "  filepath = path + group + '/Inertial Signals/'\n",
        "  filenames = list()\n",
        "  filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt'] + \\\n",
        "               ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt'] + \\\n",
        "               ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "  # inputs\n",
        "  X = load_group(filenames, filepath)\n",
        "  # output (class)\n",
        "  Y = load_file(path + group + '/y_'+group+'.txt')\n",
        "  return X, Y\n",
        "\n",
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset(path='UCI HAR Dataset/'):\n",
        "  # load all train\n",
        "  X_train, Y_train = load_XY('train', path)\n",
        "  X_test,  Y_test  = load_XY('test', path)\n",
        "  Y_train = to_categorical(Y_train - 1 ) # we need -1 to scale the categories between 0..5 (from 1..6)\n",
        "  Y_test  = to_categorical(Y_test - 1 ) # we need -1 to scale the categories between 0..5 (from 1..6)\n",
        "  return X_train, Y_train, X_test, Y_test"
      ],
      "metadata": {
        "id": "1boApy2lLnhT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_test, Y_test = load_dataset()"
      ],
      "metadata": {
        "id": "l8hh4QYmMMtS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo97vqf3BwRN",
        "outputId": "89bf47f5-531d-4cc5-ddf6-a18db3cb954b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7352, 128, 9), (7352, 6), (2947, 128, 9), (2947, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train[0],"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtGQzkLmCKbL",
        "outputId": "eb39b306-6d25-41c0-b7b1-9d7907abbe07"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 0., 0., 0., 1., 0.], dtype=float32),)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Data exploration: target variable - exercise 1\n",
        "Let's check how many data instances there are for each class:"
      ],
      "metadata": {
        "id": "Js-7BztvQ7Dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"No. of instance belong to class 0:\", np.count_nonzero(np.argmax(Y_train,axis=1)==0))\n",
        "print(\"No. of instance belong to class 1:\", np.count_nonzero(np.argmax(Y_train,axis=1)==1))\n",
        "print(\"No. of instance belong to class 2:\", np.count_nonzero(np.argmax(Y_train,axis=1)==2))\n",
        "print(\"No. of instance belong to class 3:\", np.count_nonzero(np.argmax(Y_train,axis=1)==3))\n",
        "print(\"No. of instance belong to class 4:\", np.count_nonzero(np.argmax(Y_train,axis=1)==4))\n",
        "print(\"No. of instance belong to class 5:\", np.count_nonzero(np.argmax(Y_train,axis=1)==5))"
      ],
      "metadata": {
        "id": "4PTSOP--jPe_",
        "outputId": "ffaf5e7c-8aef-45f1-ed9d-1127a1dadb4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of instance belong to class 0: 1226\n",
            "No. of instance belong to class 1: 1073\n",
            "No. of instance belong to class 2: 986\n",
            "No. of instance belong to class 3: 1286\n",
            "No. of instance belong to class 4: 1374\n",
            "No. of instance belong to class 5: 1407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can doublecheck your calculations by plotting the histogram of the target variables: "
      ],
      "metadata": {
        "id": "VaeV8Nqzjd6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(np.argmax(Y_train,axis=1))"
      ],
      "metadata": {
        "id": "4JTkOAmpRGKT",
        "outputId": "18bc1210-7b49-4eaf-f204-02962ee9c74e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Count'>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Data exploration: input variables - exercise 2\n",
        "And now let's select one instance from each class and plot the corresponding timeseries:"
      ],
      "metadata": {
        "id": "rVeZhkJ-RB4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 6))\n",
        "\n",
        "for i in range(2): # row\n",
        "  for k in range(3): # column\n",
        "    for l in range(X_train.shape[2]): # dimensons to be displayed\n",
        "      class_no=i*3+k\n",
        "      axs[i,k].plot(X_train[np.where(Y_train[:, class_no]==1)[0][0], :, :])\n",
        "      axs[i,k].title.set_text(\"Class \"+str(class_no))\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "C_wmgDBDWpFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB0t_uW4XK2z"
      },
      "source": [
        "## 4. Model definition and training - exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U04cYnapXK26"
      },
      "source": [
        "Let's define and train a 1D convolutional neural network, with the multidimensional timeseries as inputs, and the class in one-hot encoding as output. \n",
        "\n",
        "This time your task is to correct the code below and achieve higher than 90% validation accuracy and test accuracy. The test accuracy is calculated in section 5. \n",
        "Currently, **there are many errors (both syntactical and theroetical) in the model definition, compile and fit parts**, that should be fixed to achieve the goal. Don't change the number of layers and the layer types, and validation_split, just the other hyperparameters. There are several good solutions!\n",
        "\n",
        "Hints: \n",
        "* use narrow and deep Conv1D kernels\n",
        "* use standard activation functions for the inner layers (e.g. relu, sigmoid, tanh) with the corresponding initialization method\n",
        "* use the appropriate activation function the output and the corresponding loss function (which is aligned with the classification task)\n",
        "* use regularization, but not too agressive\n",
        "* use standard optimizers\n",
        "* train in mini-batches"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_filter       = 48   # number of filter/kernels in the convolutional layers\n",
        "filter_length   = 3  # length of the filter/kernel in the convolutional layers\n",
        "window_size     = X_train.shape[1] # the window size defined by the dataset\n",
        "nb_features     = X_train.shape[2] # the number of features of the input data\n",
        "nb_outputs      = Y_train.shape[1] # the number of outputs (defined by the target data)"
      ],
      "metadata": {
        "id": "Yokac5NUR003"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=nb_filter, kernel_size=filter_length, activation='relu', kernel_initializer='he_normal', input_shape=(window_size, nb_features)))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(filters=nb_filter, kernel_size=filter_length, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(nb_outputs, activation='softmax'))"
      ],
      "metadata": {
        "id": "N3h94EJTRxSy"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model with the appropriate loss function for multiclass classification."
      ],
      "metadata": {
        "id": "CxUOZGFVWZik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "kJ5dVKuzSh-U"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "692uD8KASsi6",
        "outputId": "d00cebd9-26a4-4ca1-ecfe-60f5180c140b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_14 (Conv1D)          (None, 126, 48)           1344      \n",
            "                                                                 \n",
            " max_pooling1d_11 (MaxPoolin  (None, 63, 48)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 63, 48)            0         \n",
            "                                                                 \n",
            " conv1d_15 (Conv1D)          (None, 61, 48)            6960      \n",
            "                                                                 \n",
            " max_pooling1d_12 (MaxPoolin  (None, 30, 48)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 30, 48)            0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 1440)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               184448    \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 193,526\n",
            "Trainable params: 193,526\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(patience=40, restore_best_weights=True, monitor=\"validation_loss\")"
      ],
      "metadata": {
        "id": "F2K-4bVKSz85"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we run the training:"
      ],
      "metadata": {
        "id": "0cT9S6rrbTFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, \n",
        "          epochs=50, batch_size=1, \n",
        "          validation_split=0.2, # don't change the validation split\n",
        "          callbacks=[es],\n",
        "          verbose=2)"
      ],
      "metadata": {
        "id": "JSeo-uv2SnAj",
        "outputId": "d167ee4f-e3d8-4a2a-9fab-b0b498406cb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 112s - loss: 0.4243 - accuracy: 0.8318 - val_loss: 0.3975 - val_accuracy: 0.9014 - 112s/epoch - 19ms/step\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 21s - loss: 0.1458 - accuracy: 0.9430 - val_loss: 0.4701 - val_accuracy: 0.8967 - 21s/epoch - 4ms/step\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1427 - accuracy: 0.9449 - val_loss: 0.5826 - val_accuracy: 0.9103 - 20s/epoch - 3ms/step\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 23s - loss: 0.1303 - accuracy: 0.9485 - val_loss: 0.5983 - val_accuracy: 0.8892 - 23s/epoch - 4ms/step\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 21s - loss: 0.1170 - accuracy: 0.9509 - val_loss: 0.8490 - val_accuracy: 0.8885 - 21s/epoch - 4ms/step\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 22s - loss: 0.1206 - accuracy: 0.9502 - val_loss: 0.9395 - val_accuracy: 0.8953 - 22s/epoch - 4ms/step\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 22s - loss: 0.1158 - accuracy: 0.9566 - val_loss: 0.7575 - val_accuracy: 0.8885 - 22s/epoch - 4ms/step\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1228 - accuracy: 0.9534 - val_loss: 1.0348 - val_accuracy: 0.8810 - 20s/epoch - 3ms/step\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1285 - accuracy: 0.9549 - val_loss: 1.0901 - val_accuracy: 0.8797 - 20s/epoch - 3ms/step\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 22s - loss: 0.1206 - accuracy: 0.9512 - val_loss: 1.2787 - val_accuracy: 0.9109 - 22s/epoch - 4ms/step\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1038 - accuracy: 0.9543 - val_loss: 1.8081 - val_accuracy: 0.8933 - 20s/epoch - 3ms/step\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1335 - accuracy: 0.9531 - val_loss: 0.9421 - val_accuracy: 0.8967 - 20s/epoch - 3ms/step\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 23s - loss: 0.1123 - accuracy: 0.9543 - val_loss: 3.0567 - val_accuracy: 0.9021 - 23s/epoch - 4ms/step\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 22s - loss: 0.1151 - accuracy: 0.9582 - val_loss: 1.4802 - val_accuracy: 0.8885 - 22s/epoch - 4ms/step\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1003 - accuracy: 0.9563 - val_loss: 2.3606 - val_accuracy: 0.8933 - 20s/epoch - 3ms/step\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 23s - loss: 0.0834 - accuracy: 0.9609 - val_loss: 3.7477 - val_accuracy: 0.9150 - 23s/epoch - 4ms/step\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1391 - accuracy: 0.9524 - val_loss: 1.9759 - val_accuracy: 0.9137 - 20s/epoch - 3ms/step\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1778 - accuracy: 0.9534 - val_loss: 2.1298 - val_accuracy: 0.8783 - 20s/epoch - 3ms/step\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1364 - accuracy: 0.9583 - val_loss: 1.5603 - val_accuracy: 0.8960 - 20s/epoch - 3ms/step\n",
            "Epoch 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.0994 - accuracy: 0.9604 - val_loss: 2.6232 - val_accuracy: 0.9157 - 20s/epoch - 3ms/step\n",
            "Epoch 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1479 - accuracy: 0.9594 - val_loss: 2.5497 - val_accuracy: 0.8973 - 20s/epoch - 3ms/step\n",
            "Epoch 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1112 - accuracy: 0.9626 - val_loss: 1.7135 - val_accuracy: 0.8933 - 20s/epoch - 3ms/step\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1887 - accuracy: 0.9590 - val_loss: 1.9290 - val_accuracy: 0.8885 - 20s/epoch - 3ms/step\n",
            "Epoch 24/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 22s - loss: 0.1388 - accuracy: 0.9587 - val_loss: 1.4053 - val_accuracy: 0.9137 - 22s/epoch - 4ms/step\n",
            "Epoch 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1451 - accuracy: 0.9606 - val_loss: 1.3297 - val_accuracy: 0.8892 - 20s/epoch - 3ms/step\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1065 - accuracy: 0.9609 - val_loss: 1.9113 - val_accuracy: 0.9137 - 20s/epoch - 3ms/step\n",
            "Epoch 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1192 - accuracy: 0.9614 - val_loss: 1.4411 - val_accuracy: 0.8953 - 20s/epoch - 3ms/step\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1661 - accuracy: 0.9643 - val_loss: 1.3596 - val_accuracy: 0.9021 - 20s/epoch - 3ms/step\n",
            "Epoch 29/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1591 - accuracy: 0.9611 - val_loss: 1.7587 - val_accuracy: 0.8858 - 20s/epoch - 3ms/step\n",
            "Epoch 30/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 22s - loss: 0.0841 - accuracy: 0.9657 - val_loss: 1.5910 - val_accuracy: 0.9028 - 22s/epoch - 4ms/step\n",
            "Epoch 31/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 22s - loss: 0.1434 - accuracy: 0.9623 - val_loss: 10.3730 - val_accuracy: 0.9123 - 22s/epoch - 4ms/step\n",
            "Epoch 32/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1280 - accuracy: 0.9619 - val_loss: 4.7404 - val_accuracy: 0.9130 - 20s/epoch - 3ms/step\n",
            "Epoch 33/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1796 - accuracy: 0.9589 - val_loss: 3.3402 - val_accuracy: 0.9109 - 20s/epoch - 3ms/step\n",
            "Epoch 34/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 21s - loss: 0.1442 - accuracy: 0.9577 - val_loss: 2.7121 - val_accuracy: 0.8912 - 21s/epoch - 4ms/step\n",
            "Epoch 35/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1124 - accuracy: 0.9565 - val_loss: 15.0469 - val_accuracy: 0.8851 - 20s/epoch - 3ms/step\n",
            "Epoch 36/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1385 - accuracy: 0.9556 - val_loss: 7.1633 - val_accuracy: 0.8987 - 20s/epoch - 3ms/step\n",
            "Epoch 37/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1465 - accuracy: 0.9566 - val_loss: 8.9078 - val_accuracy: 0.8824 - 20s/epoch - 3ms/step\n",
            "Epoch 38/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1203 - accuracy: 0.9611 - val_loss: 9.9908 - val_accuracy: 0.8804 - 20s/epoch - 3ms/step\n",
            "Epoch 39/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1136 - accuracy: 0.9645 - val_loss: 12.9301 - val_accuracy: 0.8919 - 20s/epoch - 3ms/step\n",
            "Epoch 40/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.3122 - accuracy: 0.9614 - val_loss: 9.2997 - val_accuracy: 0.8572 - 20s/epoch - 3ms/step\n",
            "Epoch 41/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1307 - accuracy: 0.9600 - val_loss: 16.6706 - val_accuracy: 0.8926 - 20s/epoch - 3ms/step\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1530 - accuracy: 0.9607 - val_loss: 14.1579 - val_accuracy: 0.9184 - 20s/epoch - 3ms/step\n",
            "Epoch 43/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.2009 - accuracy: 0.9514 - val_loss: 2.9562 - val_accuracy: 0.8831 - 20s/epoch - 3ms/step\n",
            "Epoch 44/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 22s - loss: 0.1328 - accuracy: 0.9617 - val_loss: 7.1664 - val_accuracy: 0.8899 - 22s/epoch - 4ms/step\n",
            "Epoch 45/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1554 - accuracy: 0.9638 - val_loss: 9.2333 - val_accuracy: 0.9123 - 20s/epoch - 3ms/step\n",
            "Epoch 46/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1023 - accuracy: 0.9621 - val_loss: 2.4987 - val_accuracy: 0.9021 - 20s/epoch - 3ms/step\n",
            "Epoch 47/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 23s - loss: 0.1921 - accuracy: 0.9577 - val_loss: 7.7262 - val_accuracy: 0.8559 - 23s/epoch - 4ms/step\n",
            "Epoch 48/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 21s - loss: 0.1916 - accuracy: 0.9580 - val_loss: 3.0873 - val_accuracy: 0.8939 - 21s/epoch - 4ms/step\n",
            "Epoch 49/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 23s - loss: 0.1361 - accuracy: 0.9641 - val_loss: 8.4077 - val_accuracy: 0.9177 - 23s/epoch - 4ms/step\n",
            "Epoch 50/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `validation_loss` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5881/5881 - 20s - loss: 0.1314 - accuracy: 0.9515 - val_loss: 7.1438 - val_accuracy: 0.8824 - 20s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6f313caa60>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXM0IetJSpKM"
      },
      "source": [
        "## 5. Evaluation\n",
        "Please run the cells below to check the test loss and test accuracy (remember, the accuracy must be over 90%) and inspect the other evaluation methods as well. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval = model.evaluate(X_test,Y_test)\n",
        "print(\"Test loss:\",eval[0])\n",
        "print(\"Test accuracy:\",eval[1])"
      ],
      "metadata": {
        "id": "7sR4-0Rkaz1-",
        "outputId": "ee404461-0694-496a-98f7-0d8093f3d38f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93/93 [==============================] - 0s 3ms/step - loss: 4.8277 - accuracy: 0.9040\n",
            "Test loss: 4.82765007019043\n",
            "Test accuracy: 0.9039701223373413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "WJDwjNkAaS8n"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(X_test)"
      ],
      "metadata": {
        "id": "rkIBcKY9aMdp",
        "outputId": "ca1408a5-e3f7-46d3-e597-53763d9df9ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93/93 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(np.argmax(Y_test,1),np.argmax(preds,1)))"
      ],
      "metadata": {
        "id": "zrWe3vPJaZ3v",
        "outputId": "6fb71732-3787-4483-d225-25303bcb9c14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.96       496\n",
            "           1       0.92      0.93      0.93       471\n",
            "           2       0.90      0.99      0.95       420\n",
            "           3       0.75      0.91      0.82       491\n",
            "           4       0.92      0.71      0.80       532\n",
            "           5       1.00      0.95      0.97       537\n",
            "\n",
            "    accuracy                           0.90      2947\n",
            "   macro avg       0.91      0.91      0.90      2947\n",
            "weighted avg       0.91      0.90      0.90      2947\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf=confusion_matrix(np.argmax(Y_test,1),np.argmax(preds,1))\n",
        "sns.heatmap(conf, annot=True, fmt='d', vmax=100)"
      ],
      "metadata": {
        "id": "kRdfXOypaciv",
        "outputId": "44485441-3ac7-40c9-8a5c-7ff0ef587371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}